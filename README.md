# Memory-Enhanced Machine Learning Models for Music Generation
We present an array of generative machine learning models for the purpose of modeling and generating music. We also explore a number of different representations of musical data, some of which work significantly better than the others. Furthermore, we present a novel extension of traditional Markov chains for this specific task and analyze its performance quantitatively.

The project was undertaken as a part of the [Fall-2018 Introduction to Machine Learning (10-701)](http://www.cs.cmu.edu/~pradeepr/701/) course offered by the School of Computer Science, Carnegie Mellon University. The paper can be found [here](paper/project_report.pdf).

## Prerequisites
* [Numpy](https://github.com/numpy/numpy)
* [music21](https://github.com/cuthbertLab/music21)
* [PyTorch 0.4.1](https://github.com/pytorch/pytorch)
* [Pypianoroll](https://github.com/salu133445/pypianoroll)

## Datasets
* [Piano-midi.de](http://www.piano-midi.de/)
* [Nottingham](https://ifdo.ca/~seymour/nottingham/nottingham.html)
* [MuseData](http://www.musedata.org/)
* [JSB Chorales](https://github.com/johndpope/allan-harmony)

## Authors
* [Ramesh Balaji](https://github.com/rameshrudx)
* [Stefani Karp](https://github.com/skarp)
* [Tanmaya Dabral](https://github.com/many-facedgod)

